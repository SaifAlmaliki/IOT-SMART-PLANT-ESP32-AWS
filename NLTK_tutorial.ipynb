{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLTK tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPQfc2Xmpo+Xn+8PHUpLVkm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saifwesam2007/AWS-IOT-SMART-PLANT-ESP32/blob/master/NLTK_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9TYSm7iMClh",
        "outputId": "99e6b00d-a4cd-4c82-f969-24eb7183fa4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pip install nltk"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcvH8GA1MT85"
      },
      "source": [
        "import nltk"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVndlfG-MZvl",
        "outputId": "b142f6b3-47aa-4ee4-a4db-ff3cf90636ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Library to Tokenize by punkt\n",
        "nltk.download('punkt')  \n",
        "\n",
        "# Library to Tokenize by wordnet\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Library to Tokenize by stopword\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Library to Tokenize by POS TAG\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EU-OpMZjPWSU"
      },
      "source": [
        "**1. NLTK Sentence Tokenizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "souPcPwdNZtk"
      },
      "source": [
        "myText=\"Today is a great day. It is even better than yesterday. And yesterday was the best day ever.\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHU27oSqNBcI",
        "outputId": "0bc8933f-e9ab-4dee-a41c-32c6ae6dd11a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Letâ€™s try tokenizing a sentence.\n",
        "from nltk.tokenize import sent_tokenize\n",
        "sent_tokenize(myText)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Today is a great day.',\n",
              " 'It is even better than yesterday.',\n",
              " 'And yesterday was the best day ever.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fneoll3aOD67",
        "outputId": "d47fb070-c156-470b-cd4c-5a4d3468d2c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Another test sentence\n",
        "sent_tokenize(\"Hi, how are you? I'm good, you? Great!\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hi, how are you?', \"I'm good, you?\", 'Great!']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LYmdR8kObCZ",
        "outputId": "857b2052-b6df-4ac3-bfce-fbbfc994645e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Another test sentence\n",
        "nltk.sent_tokenize(\"Last night, I went to Mrs. Martinez's housewarming. It was a disaster.\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Last night, I went to Mrs. Martinez's housewarming.\", 'It was a disaster.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QJyyJLSPDEN",
        "outputId": "6fff61d7-c575-4732-baa9-c018e74fe65d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# One issue we face while tokenizing is abbreviations\n",
        "# That was supposed to be one complete sentence it split into two.\n",
        "sent_tokenize(\"She holds an MDS. in Oral Pathology\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['She holds an MDS.', 'in Oral Pathology']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "475ONwItPNp7"
      },
      "source": [
        "**2. NLTK Word Tokenizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2DSh_35PQOh",
        "outputId": "9873fdd6-ec33-44d6-f0a0-cc303d45ef2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "nltk.word_tokenize(myText)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Today',\n",
              " 'is',\n",
              " 'a',\n",
              " 'great',\n",
              " 'day',\n",
              " '.',\n",
              " 'It',\n",
              " 'is',\n",
              " 'even',\n",
              " 'better',\n",
              " 'than',\n",
              " 'yesterday',\n",
              " '.',\n",
              " 'And',\n",
              " 'yesterday',\n",
              " 'was',\n",
              " 'the',\n",
              " 'best',\n",
              " 'day',\n",
              " 'ever',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgpTK1qtPv5b",
        "outputId": "a59c8668-1488-46d7-ecc8-219b9c29a960",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "nltk.word_tokenize(\"Last night, I went to Mrs. Martinez's housewarming. It was a disaster.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Last',\n",
              " 'night',\n",
              " ',',\n",
              " 'I',\n",
              " 'went',\n",
              " 'to',\n",
              " 'Mrs.',\n",
              " 'Martinez',\n",
              " \"'s\",\n",
              " 'housewarming',\n",
              " '.',\n",
              " 'It',\n",
              " 'was',\n",
              " 'a',\n",
              " 'disaster',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipbMdtMLZX7R"
      },
      "source": [
        "**Find Synonyms From NLTK WordNet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8cpWy5-P7F2",
        "outputId": "4c74d150-e227-4a01-9932-1c32d15660c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# WordNet is an NLP database with synonyms, antonyms, and brief definitions.\n",
        "\n",
        "from nltk.corpus import wordnet\n",
        "syn  = wordnet.synsets('love')\n",
        "syn"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('love.n.01'),\n",
              " Synset('love.n.02'),\n",
              " Synset('beloved.n.01'),\n",
              " Synset('love.n.04'),\n",
              " Synset('love.n.05'),\n",
              " Synset('sexual_love.n.02'),\n",
              " Synset('love.v.01'),\n",
              " Synset('love.v.02'),\n",
              " Synset('love.v.03'),\n",
              " Synset('sleep_together.v.01')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeufYYXfQ8YX",
        "outputId": "33ac8bd9-8d7e-47ae-96b1-e5f5de0525b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# brief definitions\n",
        "\n",
        "syn[4].definition()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'a score of zero in tennis or squash'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zz4Ya072RM5i",
        "outputId": "88c9d472-4197-4d8a-981e-ad5ab9bf7f5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "syn[5].examples()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['his lovemaking disgusted her',\n",
              " \"he hadn't had any love in months\",\n",
              " 'he has a very complicated love life']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrY-h3tjRq6_",
        "outputId": "155fde5e-f038-41b0-bd06-fd0c7fd7c525",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# DO you know the meaning of 'Life'\n",
        "syn = wordnet.synsets('life')\n",
        "syn[0].definition()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'a characteristic state or mode of living'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIny095ZR81G",
        "outputId": "43c06d71-9df7-4993-e53a-6c7398a0a11d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "syn[0].examples()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['social life', 'city life', 'real life']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HypBLbV-SEec",
        "outputId": "5c8b8515-ca62-4d2e-b2ce-d97b30db100b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "syn=wordnet.synsets('AI')\n",
        "syn"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('army_intelligence.n.01'),\n",
              " Synset('artificial_intelligence.n.01'),\n",
              " Synset('three-toed_sloth.n.01'),\n",
              " Synset('artificial_insemination.n.01')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFf8yc6QSJVt",
        "outputId": "874cc928-35a5-446e-cfe4-5a8b8b8101e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "syn[1].definition()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'the branch of computer science that deal with writing computer programs that can solve problems creatively'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zv8ffCHBSSIj",
        "outputId": "a98343cb-61f0-48ab-ff60-a269888a8da0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "syn[1].examples()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['workers in AI hope to imitate or duplicate intelligence in computers and robots']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7uEMXKNSacU",
        "outputId": "8b117523-bb7c-4dcd-e0be-612a189f46b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# To get the list of synonyms:\n",
        "synonyms = []\n",
        "for syn in wordnet.synsets('AI'):\n",
        "  for lemma in syn.lemmas():\n",
        "    synonyms.append(lemma.name())\n",
        "synonyms"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Army_Intelligence',\n",
              " 'AI',\n",
              " 'artificial_intelligence',\n",
              " 'AI',\n",
              " 'three-toed_sloth',\n",
              " 'ai',\n",
              " 'Bradypus_tridactylus',\n",
              " 'artificial_insemination',\n",
              " 'AI']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVh6ir1CZg6J"
      },
      "source": [
        "**Find Antonyms From NLTK WordNet**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbOjGMDAZfKR",
        "outputId": "f74a4020-a34a-46cd-da05-8bc549ad8b81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# To get the list of antonyms, we first need to check the lemmas- are there antonyms?\n",
        "from nltk.corpus import  wordnet\n",
        "antonyms = []\n",
        "for syn in wordnet.synsets('depressed'):\n",
        "  for lem in syn.lemmas():\n",
        "    if lem.antonyms():\n",
        "      antonyms.append(lem.antonyms()[0].name())\n",
        "antonyms"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['elate']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2h0EFZLapQz",
        "outputId": "1cf7a803-ae59-49af-b2a7-f6efd383b604",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# One more\n",
        "for syn in wordnet.synsets('ugly'):\n",
        "  for lem in syn.lemmas():\n",
        "    if lem.antonyms():\n",
        "      antonyms.append(lem.antonyms()[0].name())\n",
        "antonyms"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['elate', 'beautiful']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tk7xzKCrbMcl"
      },
      "source": [
        "**Stemming NLTK**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTmNezqtb7Xa"
      },
      "source": [
        "# import PorterStemmer\n",
        "from nltk.stem import PorterStemmer\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHsCn1HRbRKk",
        "outputId": "a8a02cb5-5c84-4899-f409-d6230bba921f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "ps=PorterStemmer()\n",
        "\n",
        "ps.stem('loving')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'love'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYcukTPCbN0L",
        "outputId": "596b0b5e-27f0-4133-f405-7f030a93cefa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "ps.stem('trainee')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'traine'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkfd6E0GcksH",
        "outputId": "e53b568c-ae4f-45a9-de28-53a25ad0f764",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "ps.stem('criteria')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'criteria'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnFkpmfQcsfo"
      },
      "source": [
        "**Stemming Words from Other Languages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGt3ppOhcuif",
        "outputId": "fe9c2e2d-57ae-4d46-87d8-7cc23633caec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Display Languages\n",
        "from nltk.stem import SnowballStemmer\n",
        "SnowballStemmer.languages"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('arabic',\n",
              " 'danish',\n",
              " 'dutch',\n",
              " 'english',\n",
              " 'finnish',\n",
              " 'french',\n",
              " 'german',\n",
              " 'hungarian',\n",
              " 'italian',\n",
              " 'norwegian',\n",
              " 'porter',\n",
              " 'portuguese',\n",
              " 'romanian',\n",
              " 'russian',\n",
              " 'spanish',\n",
              " 'swedish')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHSMxME3dVFq",
        "outputId": "46beca59-ebfe-4fcf-d9ab-cf29bf603103",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "rom_stemmer = SnowballStemmer('german')\n",
        "rom_stemmer.stem('termin')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'termin'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gC3SlubreA-9"
      },
      "source": [
        "**Lemmatizing NLTK Using WordNet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_VNeD5YeGBe",
        "outputId": "7e2c397d-6736-45fc-9f06-677b4c634ab8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatizer.lemmatize('believes')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'belief'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNDTOEQSfGL0",
        "outputId": "24aade29-7e37-479c-b689-5ba2546ac05f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#  to work with a verb (believes) instead of a noun (belief), use the â€˜posâ€™ argument-\n",
        "lemmatizer.lemmatize('believes', pos='v')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'believe'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnFXZfWTfgOQ",
        "outputId": "1c9e608a-78be-4b2a-bbe3-29f424051eba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# pos=v ==> verb\n",
        "# pos=n ==> none\n",
        "lemmatizer.lemmatize('crossing', pos='v')\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cross'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cVBvimYfw5Y",
        "outputId": "4a258e0a-41f0-48f8-d5e0-698e0edae96b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# to get none\n",
        "lemmatizer.lemmatize('crossing', pos='n')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'crossing'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zwy6QC6cf6-K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5C_DoKaf72a"
      },
      "source": [
        "**NLTK Stop Words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FH-woN1sf9MI",
        "outputId": "c370f3cd-2086-4d02-d683-1a72ae9b62ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stopwords.words('english')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJS-7Bn8ggQt"
      },
      "source": [
        "text=\"Today is a great day. It is even better than yesterday. And yesterday was the best day ever!\""
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkWNo12PjAli",
        "outputId": "3ba4f9f3-f7b5-4347-9619-252592286139",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stopwords = set(stopwords.words('english'))\n",
        "from nltk.tokenize import word_tokenize\n",
        "words = word_tokenize(text)\n",
        "\n",
        "wordsFiltered = []\n",
        "for w in words:\n",
        "  if w not in stopwords:\n",
        "    wordsFiltered.append(w)\n",
        "\n",
        "wordsFiltered"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Today',\n",
              " 'great',\n",
              " 'day',\n",
              " '.',\n",
              " 'It',\n",
              " 'even',\n",
              " 'better',\n",
              " 'yesterday',\n",
              " '.',\n",
              " 'And',\n",
              " 'yesterday',\n",
              " 'best',\n",
              " 'day',\n",
              " 'ever',\n",
              " '!']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNn9PD7Uj7U2"
      },
      "source": [
        "**Speech Tagging**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5AbYPDdj6ey",
        "outputId": "ecf52698-5ae1-4f2a-e943-3ec1a974034e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.tokenize import PunktSentenceTokenizer\n",
        "text='I am a human being, capable of doing terrible things'\n",
        "sentences = nltk.sent_tokenize(text)\n",
        "for s in sentences:\n",
        "  print(nltk.pos_tag(nltk.word_tokenize(s)))\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('I', 'PRP'), ('am', 'VBP'), ('a', 'DT'), ('human', 'JJ'), ('being', 'VBG'), (',', ','), ('capable', 'JJ'), ('of', 'IN'), ('doing', 'VBG'), ('terrible', 'JJ'), ('things', 'NNS')]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}